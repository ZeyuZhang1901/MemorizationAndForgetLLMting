{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DPO on News Memorization\n",
    "\n",
    "This file is to run direct policy optimization (DPO) on the news memorization dataset for the purpose of memorization and forgetting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import torch\n",
    "from transformers import BitsAndBytesConfig, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from trl import DPOConfig, DPOTrainer\n",
    "from peft import PeftModel\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the huggingface key\n",
    "import json\n",
    "with open('../apikeys.json', 'r') as f:\n",
    "    apikeys = json.load(f)\n",
    "hf_key = apikeys['hf_api_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Config for DPO Training\n",
    "\n",
    "Before the formal training, we need to setup the config for the DPO training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import LoraConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DPO General Configs\n",
    "dpo_model_name = \"meta-llama/Meta-Llama-3-8B\"\n",
    "dpo_data_dir = \"../datasets/latest_news/latest_news_memorization.csv\"\n",
    "dpo_output_dir = \"./dpo_models/latest_news_memorization\"\n",
    "dpo_log_dir = \"./dpo_logs/latest_news_memorization\"\n",
    "sft_adapter_dir = \"./sft_models/latest_news_memorization\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bnb Configs\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = DPOConfig(output_dir=dpo_output_dir, \n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=1,\n",
    "    logging_steps=10,\n",
    "    learning_rate=2e-4,\n",
    "    eval_strategy=\"no\",\n",
    "    eval_steps=10,\n",
    "    bf16=True,\n",
    "    lr_scheduler_type='cosine',\n",
    "    warmup_ratio=0.05,  # warmup ratio\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "    output_dir=dpo_output_dir,\n",
    "    logging_dir=dpo_log_dir,\n",
    ")\n",
    "\n",
    "generate_max_length = 512\n",
    "tokenizer_max_length = 512"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
